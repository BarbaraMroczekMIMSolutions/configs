KONSOLA:

ustawienie basha jako domyślnego shella:
cat /etc/shells  # lista dostępnych shelli
chsh -s /bin/bash

copy, paste:
ctrl+shift+c, ctrl+shift+v

wyszukaj w historii:
ctrl+r # wielokrotności pokażą coraz starsze
anuluj:
ctrl+g
wróć do nowszego:
ctrl+s

ustawienie taba jako cykliczne autocomplete:
    ustawienia żyją w ~/.inputrc

    $include /etc/inputrc
    # Make Tab cycle between possible completions
    # Cycle forward: Tab
    # Cycle backward: Shift-Tab
    TAB: menu-complete
    "\e[Z": menu-complete-backward
    # Make C-q display the list of possible completions
    Control-q: complete
    # Display the list of matches when no further completion is possible
    set show-all-if-unmodified on

zrestartuj network-menagera:
sudo systemctl restart network-manager.service

zamontuj pliki przez ssh do lokalnego folderu:
    nie działa z symlinkiem, trzeba podać adres źródła; działają aliasy ssh
sshfs bmroczek@motyka.mimuw.edu.pl:/home/bmroczek ./motyka
    # ~ się nie rozwija; można użyć aliasu z .ssh/config zamiast user@server
odmontuj:
umount ./motyka

klucze ssh:
wygeneruj:
ssh-keygen -C komentarz
ssh-keygen -t ed25519 -C "barbara.mroczek@mim.ai" -f ~/.ssh/mimsolutions.id_ed25519
skopiuj:
ssh-copy-id user@host  # dodaje do ~/.ssh/authorized_keys; opcjonalnie -n (dry run)
potrzebuje prawidłowych uprawnień ~ oraz ~/.ssh
potrzebuje klonowania repo przez ssh, nie http

Bad owner or permissions on ~/.ssh/config:
chmod 600 ~/.ssh/config
chown $USER ~/.ssh/config

prześlij plik przez ssh:
scp username@from_host:file.txt /local/directory/
scp file.txt username@to_host:/remote/directory/
scp -r username@from_host:/remote/directory/ /local/directory/
scp -r /local/directory/ username@to_host:/remote/directory/
scp username@from_host:/remote/directory/file.txt username@to_host:/remote/directory/

skopiuj potrzebne hooks (do nowego repo):
cp docker/git-hooks/* <projectDir>/.git/hooks
scp -p -P 29418 <login>@siekiera.mimuw.edu.pl:hooks/commit-msg <projectDir>/.git/hooks/

sprawdź, czy biblioteka pythonowa jest zainstalowana (tutaj redis):
pip list | grep redis

zapisz listę zainstalowaynch bibliotek:
pip list --format=freeze > env_name_requirements.txt
# pip freeze wypisuje biblioteki instalowane przez condę jako
# amqp @ file:///home/conda/feedstock_root/build_artifacts/amqp_1591005859311/work
# source: https://stackoverflow.com/q/62863020

sprawdź, gdzie są pliki konkretnego liba:
    czasem warto sprawdzić autorstwo tych plików oraz czy nie znajdują się w local, czyli
    poza folderem środowiska
w pythonie:
    import pakiet
    print(pakiet.__path__)
    print(pakiet.__file__)
pip show <pakiet>


zezwól na zmiany w folderze/pliku przez ipython:
chown bmroczek:approx filename/foldername

zmień tylko grupę:
chgrp <nazwa_grupy> <nazwa_pliku>  # -R rekusywnie
popraw właścicieli:
chown -R bmroczek:approx . && chown -R bmroczek:approx * && chmod g+s .
tylko jeśli był konkretny:
sudo chown -R --from pwygocki bmroczek .
zmień tylko foldery:
find /path/to/base/dir -type d -exec chmod g+s {} \;
zmień tylko pliki:
find /path/to/base/dir -type f -exec chmod 644 {} \;
Jeśli w dostępie mam g=r-S, to setgid działa, ale grupa nie ma dostępu. Najłatwiej to naprawić przez:
# +X doda wykonywalność tylko do folderów i plików, które są wykonywalne dla użytkownika bądź pozostałych, w przeciwieństwie do +x
chmod -R g+X /path/to/base/dir

zawansowane uprawnienia:
JUPYTER_USER="jupyter-$USER"
MAIN_FOLDER="projects/" # seen also /srv/workspace/$USER/
setfacl -R  -d -m u:$USER:rwX $MAIN_FOLDER # default setting
setfacl -R  -m u:$USER:rwX $MAIN_FOLDER
setfacl -R  -d -m u:$JUPYTER_USER:rwX $MAIN_FOLDER
setfacl -R  -m u:$JUPYTER_USER:rwX $MAIN_FOLDER

setfacl -m u:$JUPYTER_USER:--X /home/$USER # make scripts executable for the other user

sprawdź zaawansowane uprawnienia:
getfacl FILE_OR_FOLDER

sprawdź grupy użytkownika:
id # zalogowanego użytkownika
id user_name

utwórz użytkownika:
sudo adduser USERNAME

sprawdź członków grupy:
getent group group_name
# jeśli id zwraca krótszą listę grup, to przelogowanie się tego użytkownika pomoże; w przypadku jupyterhuba warto zrestartować serwer

zmuś id do rozpoznania przynależności do grupy bez przelogowania użytkownika / restartu sesji:
exec sg <new_group_name> "newgrp $(id -gn)"

restart shella w tmuxie (też odświeża grupę, ale restartuję sesję bashową):
exec su -l $USER

zobacz wszystkie grupy:
getent group

utwórz grupę:
groupadd <nazwa_grupy>

dodaj użytkownika do grupy:
sudo usermod -a -G group_name user_name

nadaj sudo użytkownikowi:
sudo usermod -a -G sudo <user>

restart hasła użytkownika:
sudo passwd <user>

utwórz symlink:
ln -s /folderorfile/link/will/point/to /name/of/the/link
usuń jak zwykły plik:
rm /path/of/symlink

wylistuj tylko foldery:
ls -d */

wylistuj tylko ukryte pliki:
ls .[!.]?*

wylistuj tylko puste pliki:
find . -name '*.txt' -size 0

wylistuj pliki odfiltrowane po dacie:
https://stackoverflow.com/questions/158044/how-to-use-find-to-search-for-files-created-on-a-specific-date
find FOLDER_NAME -ctime TIME_PERIOD
Examples of TIME_PERIOD:
    More than 30 days ago: -ctime +30
    Less than 30 days ago: -ctime -30
    Exactly 30 days ago: -ctime 30

policz pliki w folderze (nierekurencyjnie):
ls | wc -l

struktura plików (nie rozwijaj dla folderów z >=N elementami, tylko foldery):
tree --filelimit N -d FOLDER_TO_LIST

wylistuj rekurencyjnie wszystkie pliki o nazwie zgodnej z regexem:
find . -name '*Untitled*' -print

usuń wszystkie pliki *orig (także w podfolderach):
find . -name \*.orig -delete

wylistuj moje foldery:
find . -mindepth 1 -maxdepth 1 -type d -user bmroczek

usuń znalezione pliki (foldery, pytaj o potwierdzenie):
find ... | xargs rm (-r -i)

przenieś znalezione pliki:
find /path/to/search/ -type f -name "glob-to-find-files" | xargs cp -t /target/path/

usuń puste foldery (rekurencyjnie):
find . -name ".svn" -type d -empty -delete

usuń z nadpisywaniem:
shred -zu file_name  # z: dodatkowo nadpisz zerami; u: usuń końcowe pliki

spisz checksumy wszystkich plików w folderze rekurencyjnie:
find . -type f -exec md5sum '{}' >> md5check.txt \;
porównaj te pliki:
import pandas as pd
def on_bad_line(bad_line: list[str]) -> list[str]:
    return [bad_line[0], "  ".join(bad_line[1:])]
source = pd.read_csv("md5check_source.txt", names=["sha", "file"], sep="  ", on_bad_lines=on_bad_line, engine="python")
target = pd.read_csv("md5check_target.txt", names=["sha", "file"], sep="  ", on_bad_lines=on_bad_line, engine="python")
comp = source.merge(target, on="file", suffixes=["_source", "_target"], validate="1:1")
comp[comp.sha_source != comp.sha_target]

obciążenie serwera:
htop

zużycie gpu:
(watch) nvidia-smi
gpu_usage # skrypt mim-owy?

zajętość dysku:
df -h

disk usage:
du (-hs --max-depth=1)
du -a -h --max-depth=1 | sort -hr
du -ha -d 1 -t 1MB  # -d = --max-depth; -t = --threshold

sumaryczna waga plików zgodnych z globem:
find . -name "blob_expr" -user mim -not -newermt "2024-06-01" -exec du -ch {} + | tail -n1
# -newermt to nowszy niż (uwaga na -not)

aktualny folder z rozwinięciem symlinków:
pwd -P

ściąganie pliku:
wget adres.do.pliku

temperatura:
sensors
uaktualniaj wynik:
watch sensors

wypisz wersję systemu:
cat /etc/*-release

znajdź proces:
ps aux | grep (...)
pgrep -f -a 'ross'

wypisz proces wg pid-a:
ps -p <pid> -lF ww

znajdź string w systemie plików:
# flaga '-l': lista plików zamiast wystąpień
# parametr '-C': wielkość kontekstu (linii przed i po); -A dla after; -B dla before
grep -r --include="*.json" "text to find" .

ustaw folder wykonania skryptu pythonowego:
PYTHONPATH=.
export PYTHONPATH

skompresuj listę plików zipem:
zip output_name first_file, second_file, third_file
skompresuj folder, bez info o postępie:
zip -r -q output_name directory_to_zip/
można dodać więcej folderów naraz, tak jak wiele plików
ustaw poziom kompresji (wyższe trwają dłużej, dają mniejsze outputy; wartość z zakresu 0-9):
zip -8 output_name file_to_zip
rozpakuj zipa:
unzip (-q) zip_file.zip (-d ./target/directory/path)
podejrzyj zawartość zipa:
unzip -l source_code.zip | less
rozpakuj tar.gz:
tar -xf archive.tar.gz
polskie znaki windowsowe:
unzip (-q) -O cswindows1250 <file_name>


CONDA:

conda activate ENV_NAME
conda env list
conda create --name CLONE_NAME --clone ENV_NAME
conda create --name ENV_NAME python=3.9
conda env remove -n ENV_NAME

dodanie do środowiska condowego zmiennych środowiskowych:
conda activate <my_env>
conda env config vars set ENV_VAR_NAME=env_var_value
conda env config vars list # wypisanie ustawionych zmiennych
jeśli coś pójdzie bardzo nie tak, to można próbować edytować plik ${CONDA_PREFIX}/conda-meta/state

udostępnienie jupyterowemu użytkownikowi środowiska:
1. Jako użytkownik jupyter-bmroczek utwórz plik /home/jupyter-bmroczek/.condarc z:
envs_dirs:
  - /home/bmroczek/.conda/envs
2. Jako użytkownik bmroczek upewnij się, że ipykernel jest zainstalowany:
conda activate <środowisko_condowe>
pip list | grep ipykernel
3. Jako użytkownik jupyter-bmroczek sprawdź, że conda widzi nowe środowisko:
conda env list
(uwaga: użytkownik jupyter-bmroczek nie powinien instalować niczego w tych środowiskach, bo i tak nie działa, ale twierdzi, że działa?) – chyba brakowało uprawnień, dlatego był read-only
w takim przypadku `pip install` zainstaluje pakiety np. w '/home/$USER/.local/lib/python3.9/site-packages/pandas' (do sprawdzenia w pandas.__path__)

isntalacja w środowisku, do którego dostęp wymaga sudo (każde na użytkowniku tljh):
# źródło: Instalacja kulfona w polkomtel
conda activate <środowisko usera tljh>  # wystarczy być swoim zwykłym użytkownikiem
sudo -E env PATH=${PATH} pip install <paczka>  # przekazanie zmiennych środowiskowych i zmiennej PATH, której -E nie obejmuje

wyczyszczenie nieużywanych plików:
conda clean --all
conda clean --force-pkgs-dirs
source: https://stackoverflow.com/a/64005961

sprawdzenie ustawień condy:
conda config --show

użycie condy w skrypcie bashowym:
# to działa tylko jeśli skrypt jest odpalany ze środowiska base, inaczej źle szuka środowisk
source $(conda info --base)/etc/profile.d/conda.sh

sprawdź właściwą wagę środowisk (po uwzględnieniu hardlinków):
	du -sh pkgs envs/*
prześledź hardlink:
	ls -i  # wyświetla numery inode
	find . -inum NUM  # wyszukuje wszystkie pliki linkujące do inode=NUM

budowanie wheela:
conda nadpisuje ścieżki systemowe do g++, ld i innych. Na razie jedynym rozwiązaniem jakie
znalazłam, to ubicie całej kondy i praca na venvie. Dokładniej:
1. wykomentować cały autosrat condy s ~/.bashrc
2. uruchomić świeżą konsolę (powinna byc już bez kondy
3. dopiero wtedy utworzyć środowiśko (venv my_new_venv)
4. poinstalować potrzebne rzeczy, być może także narzędzia systemowe


POETRY:

dodaj pakiet do pyproject.toml i zainstaluj w środowisku:
poetry add pandas

zainstaluj pakiety z poetry.lock:
poetry install
# domyślnie isntaluje też samą paczkę; żeby nie: --no-root

wyświetl wersję w poetry.lock:
	poetry show  # opcjonalnie nazwa pakietu; -T tylko podane bezpośrednio (top-level)

dopasowanie wersji paczki:
    ^ zachowuje tylko pierwszą cyfrę

w pełni dostosuj środowisko do poetry.lock (install + usuń pakiety spoza locka)
poetry sync

zwiększ liczbę komunikatów o błędzie (gdy instalacja zawisa):
poetry install -vvv

każ mu ignorować keyring (warto przy każdej instalacji pakietów):
export PYTHON_KEYRING_BACKEND=keyring.backends.null.Keyring

puść flake8:
poetry run flake8 .

puść isort:
poetry run isort . --check-only

puść testy:
poetry run pytest

ustawienie miejsca instalacji:
# dodaj w ~/.bashrc:
export POETRY_CACHE_DIR=/u01/bmroczek/.poetry/cache
export POETRY_DATA_DIR=/u01/bmroczek/.poetry/data
export POETRY_CONFIG_DIR=/u01/bmroczek/.poetry/config

poetry config --list  # potwierdź zmiany
poetry config cache-dir /u01/bmroczek/.poetry/cache  # wymuś nowe ustawienia



wersja cudy/pytorcha:
# typ karty graficznej
lspci | grep -i nvidia  # powinno działać; można też szukać w nvidia-smi
# Compute Capability karty na stronie nvidii https://developer.nvidia.com/cuda-gpus
# wersja CUDA, która wspiera CC do odczytania w magicznej tabelce https://stackoverflow.com/a/28933055
# pasująca wersja pytorcha do wyboru https://pytorch.org/get-started/previous-versions/

Bartek twierdzi, że miał problemy z 2.0.1 - 2.1.1 i lepiej trzymać się 2.0.0
(np. pip install torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1)
    chodzi o domyślną wersję cudy 11.x (a nie >=12), czyli kompatybilną z aktualnymi sterownikami na Kulfonie. Dodatkowo poetry mu szalało na zależnościach, ale pipy będzie działać.

# przetestowanie pytorcha/cudy:
import os
gpu_id="6"
os.environ["CUDA_VISIBLE_DEVICES"] = f"{gpu_id}"
import torch
device = torch.device("cuda")
x = torch.tensor(1.0).to(device=device)
# sprawdź, czy pojawił się proces na właściwej karcie w nvidia-smi

ipython
utworzenie pliku konfiguracyjnego:
    ipython profile create
    # utworzy plik ~/.ipython/profile_default/ipython_config.py


DOCKER:

utwórz obraz:
docker build -t <nazwa obrazu> <ścieżka folderu z Dockerfilem>
# docker oczekuje, że wszystkie zasoby wykorzystywane w Dockerfile'u, np. kopiowane pliki
# znajdują się w tym folderze. Najprościej wszystko tam kopiować, podobna da się robić też
# hard-linki (soft-linki o targecie spoza katalogu nie działają)

uruchom kontener:
docker run -p 5000:5000 -d <image_name>
# -p to przekazanie portu (zewnętrzny:wewnętrzny)
# -d, --detach uruchom w tle, nie wchodź do środka

docker run --rm -it --entrypoint /bin/bash <nazwa obrazu>
# uruchom obraz interaktywnie z shellem
# --rm usuń obraz po zamknięciu
# -i, --interactive otwórz STDIN w dokerze
# -t, --tty przedstaw wejście jako terminal
# source: https://stackoverflow.com/q/30137135
# entrypoint: jaki główny proces ma być uruchomiony

wylistuj kontenery:
docker ps -a --no-trunc  # domyślnie działające, -a = wszystkie
# --no-trunc nie skracaj zawartości kolumn, przydaje się przy sprawdzaniu komendy

wylistuj obrazy:
docker image list

usuń obraz:
docker rmi <id obrazu>

usuń kontener:
docker rm <nazwa kontenera>

usuń wszystkie zatrzymane kontenery:
# czyści folder /var/lib/docker/overlay2
docker container prune

zatrzymaj kontener
docker kill <nazwa kontenera> # wysyła SIGKILL
docker stop <nazwa kontenera> # wysyła SIGTERM, czeka trochę, wysyła SIGKILL

zatrzymaj tylko wybrane (z dużą możliwością filtrowania):
docker kill $(docker ps -a -q --filter ancestor=hello_server)

analiza kontenera:
docker inspect <nazwa kontenera> # wypisz szczegóły kontenera
docker logs <nazwa kontenera> # # sprawdź logi kontenera

wejdź do kontenera:
docker exec -it <container_id> sh  # bash jest wygodniejszy, o ile jest w obrazie

restart dockerowego daemona (np. żeby przetestować restart: always):
# w zależności od sposobu instalacji dockera/systemu?
sudo systemctl restart docker
sudo service docker restart
sudo snap restart docker

wyślij jsona do biegającego serwera flaskowego:
curl -i -H "Content-Type: application/json" -X POST -d '{"userId":"1", "username": "fizz aaaa"}' http://localhost:5000/post_test


do liczenia z konsoli:
source activate mimsolutions

przekieruj strumień błędów do less:
make 2>&1 | less

schowaj wszystkie komunikaty przy uruchamianiu z konsoli:
mupdf file.pdf 2>/dev/null &

do blokady ekranu:
slock
i3lock -c 000000

screenshot (print screen):
ScreenGrab

domyślne gui file browser, document viewer:
pcmanfm (nautilius na Ubuntu), evince

do wizualizacji jsonów:
jsongrid

pulse audio volume control:
pavucontrol

uruchom cisco anyconnect:
gtk-launch com.cisco.secureclient.gui

zaloguj się jako user:
# "-" odpowiada za zmiany w środowisku (HOME, USER, LOGNAME etc.)
su - user

uruchom serwer jupitera:
jupyter notebook --notebook-dir /home/ --port=8888
(chcesz to zrobić w tmuxie, żeby móc się odłączyć)

znalezienie tokena jupytera:
jupyter server list (tylko z konta usera mim)
bądź (jaka jest różnica? ale czasem tylko to działa)
jupyter notebook list

sprawdź, co zajmuje port xyz:
lsof -i tcp:xyz

przekaż porty:
# stawia połączenie ssh, które jednocześnie nadpisuje localhost:9999 przez zdalny port 9999
# -i .ssh/key_file  żeby użyć konkretnego klucza, zwłaszcza jeśli kluczy jest dużo
ssh -L 16007:127.0.0.1:16007 -L 9999:127.0.0.1:9999 USER_NAME@SERVER_NAME

autocomplete nie działa:
podbić wersję ipython do conajmniej 7.20.0

po ustawieniu jupitera jako service systemd:
Adam: uruchomiłem mlflow i jupytera jasko serwisy systemd. Status można spradzić wywołując (nie trzeba sudo)
service NAZWA status
są jeszcze polecenia start, stop i restart - te wymagają sudo

taki serwis konfiguruje się tworząc plik w /etc/systemd/system/NAZWA.service (np. mlflow w /etc/systemd/system/mlflow.service )
po każdej zmianie w tym pliku trzeba zrobić sudo systemctl daemon-reload
no i sudo service NAZWA restart

konwersja .ipynb do .py:
jupyter nbconvert --to script --no-prompt Untitled.ipynb --output "path/to/output/file_name" # .py added blindly by the converter
konwersja .ipymb do .html:
jupyter nbconvert --to html --no-prompt --no-input noteebuk/to/convert.ipynb --output "path/to/output/file_name" # .html added blindly by the converter

ZOOM:
fix lack of opacity:
xcompmgr -c -l0 -t0 -r0 -o.00

focus follows mouse:
gsettings set org.gnome.desktop.wm.preferences focus-mode 'mouse'
default: 'click'

ustawienia LXQT:
lxqt-config
# w szczególności na przykład lxqt-config-brightness dla jasności
# oraz lubuntu-upgrader (Apply Full Upgrade) dla managera upgradów

Unfreeze console after ctrl+s: ctrl+q
Bring the job to the foreground after ctrl+z:
    jobs   # check background processes
    fg %n  # n is the job number, e.g. 1

dunst notification daemon:
dunstctl <option>
dunstctl context  # pozwala na podjęcie akcji

modyfikacja konkretnego powiadomienia:
pkill dunst; dunst -print  # sprawdź szczegóły powiadomienia
dopisz odpowiedni filtr w .config/dunst/dunstrc (źródło wzięte ze ścieżki z manuala)
pkill dunst; dunst &  # odczep dunsta od konsoli
dunstify "Test Notification" "This is a test message."  # sprawdź, czy reszta działa

sprawdzenie ustawień DNSów:
sudo resolvectl status
restart cache'ów DNSa:
sudo resolvectl flush-caches

BASH:

zamknij sesję nie zapisując historii komend: kill -9 $$
source: https://stackoverflow.com/a/49360507

nawigacja
ctrl + a  # przejdź na początek
ctrl + k  # kill line; usuń do końca linii
ctrl + e  # end; przejdź na koniec
ctrl + u  # usuń do początku linii
ctrl + w  # usuń słowo przed kursorem (kawałek, jeśli kursor w środku)
alt + d  # usuń słowo za kursorem (kawałek, jeśli w kursor w środku)

zdefiniuj tablicę:
a=("perwszy element" "drugi element" "ostatni element")

przeiteruj się przez tablicę:
for e in "${a[@]}"; do
    echo "$e"
done

przeiteruj się po plikach:
for f in ./*; do unzip "$f"; done

wstaw wszystkie opcje:
ls filename.{first_option,txt,"one more"}
można tę składnię nawet zagnieżdżać:
echo a{1..2}bc{{1..12},50,{60..62}}

tak ogólniej:
komenda ${parameter expansion} {brace expansion} glob* $(podkomenda ewaluowana wcześniej)  <(echo "przekaż plik z wynikiem tej komendy")

podstaw (jedno) wystąpienie w zmiennej $x:
${x/find/replace}

bashowe domyślne kolorowanie (ustaw zmienną według outputu; można wynik dopisać do ~/.bashrc):
dircolors -b

nadpisz TMOUT (odpowiada za automatyczne zamykanie shella) jeśli jest readonly:
    env TMOUT="" /bin/bash --noprofile --norc

cron:
# główny plik konfiguracyjny to /etc/crontab
# podstawowa instrukcja jest w komentarzach na początku
# najdrobniejsza granularność to odpalenie co 1 minutę (* * * * *)
# sprawdź ostatnią aktywność cron-a:
grep CRON /var/log/syslog | tail

sprawdź stan baterii:
upower -i /org/freedesktop/UPower/devices/battery_BAT0
# bądź zawartość plików w /sys/class/power_supply/BAT0
# stąd bierze i3status

sprawdź czas ostatniego wyłączenia komputera:
# list of system shutdown events
last -x shutdown
# ręczne przejrzenie logów
cat /var/log/syslog | grep "shutting down"

update software:
update-manager

snap update of firefox:
snap refresh --list # sprawdź, czy są jakieś aktualizacje
sudo snap refresh firefox # instalacja nowszej wersji

nowe okno chrome'a z profilem mim ai:
google-chrome --profile-directory="Default" --new-window

nowe okno chrome'a z profilem domowym:
google-chrome --profile-directory="Profile 1" --new-window

ustawienia domyślnych aplikacji:
# są dwa niezależne ustawienia:
update-alternatives --get-selections
xdg-mime query default x-scheme-handler/https

skrypt do ogarniania workspace'ów:
workspaces_manager.py <save|restore|to_main>
Powinien mieszkać w ~/bin
echo $PATH powinno potwierdzić, że ten folder jest w ścieżce. Jeśli go nie ma
    (np. jest świeżo utworzony), ~/.profile powinien go dodawać.
    Do odświeżenia: source ~/.profile

ustaw domyślny ekran (przydatne dla i3bar icon tray):
    (nazwy ekranów do podejrzenia: xrandr --listmonitors)
xrandr --output eDP --primary
xrandr --output HDMI-A-0 --primary
dołącz monitor po prawej:
xrandr --output HDMI-A-0 --auto --right-of eDP                                   
zmień kolejność ekranów:
xrandr --output eDP --right-of HDMI-A-0
odłącz monitor:
xrandr --output HDMI-A-0 --off

zapisz layout i3 do jsona:
i3-save-tree --workspace 10 > ~/workspace_10.json


KONFIGURACJE

jupyter notebook - używaj bezpośredniego adresu przy uruchamianiu:
jupyter notebook --generate-config # generate config file, output shows the path (~/.jupyter/jupyter_notebook_config.py)
# in the file change setting (do not leave trailing space just in case):
c.NotebookApp.use_redirect_file = False

ustaw permanentnie touchpad na touch to click:
# w folderze /etc/X11/xorg.conf.d utwórz plik 10-libinput.conf (liczba decyduje tylko o priorytecie)
# w pliku zawartość:
# Identifier - dowolny opis
# MatchProduct - właśwy wpis z outputu xinput --list
# można sprawdzić wszystkie ustawienia za pomocą
# xinput --list-props "DELL0A78:00 27C6:0D42 Touchpad"
Section "InputClass"
Identifier "Dell Touchpad"
MatchProduct "DELL0A78:00 27C6:0D42 Touchpad"
Option "Tapping" "true"
EndSection

zamiana Esc z Tab:
do pliku ~/.Xmodmap dopisać:
clear Lock
keysym Caps_Lock = Escape
keysym Escape = Caps_Lock
add Lock = Caps_Lock

załadowanie tego pliku (choć powinno się samo ładować po logowaniu):
xmodmap ~/.Xmodmap

wyciszenie sali konferencyjnej:
pilot z czerwonym trójkątem
wyciszyć (po lewej z przodu)


psql:
\c postgres  # połącz się z bazą postgres
\dt  # wylistuj tabele


timew
https://timewarrior.net/docs/

timew start tag
timew summary :id
timew @2 move 10:02 :fill
    :fill  # uzupełnij także przerwy przed i po
    :adjust  # skróć pozostałe interwały tam, gdzie będą nachodzić
timew @3 split
timew delete @2
timew untag @4 @3 projectB
timew tag @4 projectB1
timew join @2 @1
timew gaps
timew track 10:00 - 11:00 tag
timew start 90mins ago tag
timew start 3pm tag
timew stop 10mins ago
timew summary :id
timew modify start @13 10:15
timew modify end @2 14:23
timew modify end @4 2025-02-03T18:50
timew report totals.py :day
timew report totals.py 2025-02-03
timew report totals.py friday
timew report totals.py 18th  # watch out for 1st 2nd 3rd
